{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a9438da",
   "metadata": {},
   "source": [
    "# Contrastive training (new Trainer + evaluation)\n",
    "\n",
    "This notebook mirrors the flow of `a_preparing_training_precise_qa_halu_as_outlier(1).ipynb`, but uses:\n",
    "- `activation_research.trainer.ContrastiveTrainer` for contrastive training\n",
    "- `activation_research.metric_evaluator.HallucinationEvaluator` for clean OOD evaluation (Mahalanobis / cosine)\n",
    "\n",
    "It assumes activations + eval results are already on disk (e.g. a `.zarr` store)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbbe1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from loguru import logger\n",
    "\n",
    "from activation_logging.activation_parser import ActivationParser\n",
    "from activation_research.model import ProgressiveCompressor\n",
    "from activation_research.trainer import ContrastiveTrainer, ContrastiveTrainerConfig\n",
    "from activation_research.metric_evaluator import MultiMetricHallucinationEvaluator\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stdout, level=\"INFO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Paths (edit these for your environment) ----\n",
    "inference_json = 'shared/goodwiki_jsonv2/generation.jsonl'\n",
    "eval_json = 'shared/goodwiki.zarr/eval_results.json'\n",
    "activations_path = 'shared/goodwiki.zarr/activations.zarr'\n",
    "\n",
    "# ---- Dataset parameters ----\n",
    "backend = 'zarr'  # 'zarr' or 'wds' or 'auto'\n",
    "relevant_layers = list(range(14, 30))\n",
    "target_layers = [22, 26]  # used for embedding-based OOD evaluation\n",
    "\n",
    "# Treat one class as outlier for certain evaluations.\n",
    "# If outlier_class=1, we use non-halu samples as baseline (ID).\n",
    "outlier_class = 1\n",
    "\n",
    "# Optional: if set, one of the two views is always from this index-in-relevant_layers\n",
    "# (matches ActivationParser semantics).\n",
    "fixed_layer = None\n",
    "\n",
    "# ---- Model / training hyperparams ----\n",
    "device = 'auto'  # 'auto', 'cuda', 'cpu'\n",
    "input_dim = 4096\n",
    "final_dim = 512\n",
    "\n",
    "max_epochs = 50\n",
    "batch_size = 512\n",
    "lr = 1e-5\n",
    "temperature = 0.25\n",
    "steps_per_epoch_override = None  # e.g., 1000 for fixed steps/epoch\n",
    "\n",
    "# For no worker restart behavior, keep num_workers > 0 and persistent_workers=True.\n",
    "# Lower this if your machine is memory constrained.\n",
    "num_workers = 30\n",
    "persistent_workers = True\n",
    "\n",
    "checkpoint_dir = os.path.join('checkpoints', 'contrastive_regular')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8038da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Load metadata + build train/test datasets ----\n",
    "ap = ActivationParser(\n",
    "    inference_json=inference_json,\n",
    "    eval_json=eval_json,\n",
    "    activations_path=activations_path,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "train_dataset = ap.get_dataset(\n",
    "    'train',\n",
    "    relevant_layers=relevant_layers,\n",
    "    fixed_layer=fixed_layer,\n",
    "    backend=backend,\n",
    ")\n",
    "test_dataset = ap.get_dataset(\n",
    "    'test',\n",
    "    relevant_layers=relevant_layers,\n",
    "    fixed_layer=fixed_layer,\n",
    "    backend=backend,\n",
    ")\n",
    "\n",
    "print('train:', len(train_dataset))\n",
    "print('test :', len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a4f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Regular contrastive encoder ----\n",
    "model = ProgressiveCompressor(\n",
    "    input_dim=input_dim,\n",
    "    final_dim=final_dim,\n",
    "    input_dropout=0.3,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Train with the new Trainer API ----\n",
    "config = ContrastiveTrainerConfig(\n",
    "    max_epochs=max_epochs,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    temperature=temperature,\n",
    "    steps_per_epoch_override=steps_per_epoch_override,\n",
    "    device=device,\n",
    "    num_workers=num_workers,\n",
    "    persistent_workers=persistent_workers,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    save_every=1,\n",
    "    snapshot_every=10,\n",
    "    snapshot_keep_last=5,\n",
    "\n",
    "    # Supervised contrastive: uses `halu` labels; ignore the configured outlier class.\n",
    "    use_labels=True,\n",
    "    ignore_label=outlier_class,\n",
    "\n",
    "    # Keeps DataLoader workers alive for map-style datasets (disabled automatically for IterableDataset).\n",
    "    use_infinite_index_stream=True,\n",
    "    use_infinite_index_stream_eval=True,\n",
    ")\n",
    "print(config)\n",
    "\n",
    "trainer = ContrastiveTrainer(model, config=config)\n",
    "trainer.fit(train_dataset=train_dataset, val_dataset=test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ea4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- OOD evaluation with the new evaluator abstraction ----\n",
    "# Build an ID-only baseline dataset for embeddings (mirrors the old notebook logic).\n",
    "ap_id = ActivationParser(\n",
    "    inference_json=inference_json,\n",
    "    eval_json=eval_json,\n",
    "    activations_path=activations_path,\n",
    "    verbose=False,\n",
    ")\n",
    "if outlier_class == 0:\n",
    "    ap_id.df = ap_id.df[ap_id.df['halu']]\n",
    "elif outlier_class == 1:\n",
    "    ap_id.df = ap_id.df[~ap_id.df['halu']]\n",
    "\n",
    "train_dataset_for_inference = ap_id.get_dataset(\n",
    "    'train',\n",
    "    relevant_layers=target_layers,\n",
    "    fixed_layer=fixed_layer,\n",
    "    backend=backend,\n",
    ")\n",
    "eval_dataset = ap.get_dataset(\n",
    "    'test',\n",
    "    relevant_layers=target_layers,\n",
    "    fixed_layer=fixed_layer,\n",
    "    backend=backend,\n",
    ")\n",
    "\n",
    "# DataLoaders are used by the evaluator primarily for the `.dataset` attribute.\n",
    "train_loader_for_baseline = DataLoader(train_dataset_for_inference, batch_size=64, shuffle=False)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model_for_eval = trainer.model  # already on the right device\n",
    "\n",
    "# Multi-metric OOD evaluation using shared embeddings (computed once).\n",
    "ood_eval = MultiMetricHallucinationEvaluator(\n",
    "    activation_parser_df=ap.df,\n",
    "    train_data_loader=train_loader_for_baseline,\n",
    "    layers=None,\n",
    "    batch_size=256,\n",
    "    sub_batch_size=64,\n",
    "    device=str(trainer.device),\n",
    "    num_workers=num_workers,\n",
    "    persistent_workers=False,\n",
    "    outlier_class=outlier_class,\n",
    "    metrics=[\n",
    "        'cosine',\n",
    "        'mds',\n",
    "        {'metric': 'knn', 'kwargs': {'k': 5, 'metric': 'euclidean'}},\n",
    "    ],\n",
    ")\n",
    "ood_stats = ood_eval.compute(eval_loader, model_for_eval)\n",
    "print('OOD metrics:', ood_stats)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
